#!/usr/bin/env python3
"""
CUDA å’Œ torch.distributed å¯ç”¨æ€§æµ‹è¯•è„šæœ¬
"""
import torch
import torch.multiprocessing as mp
import os

def setup_distributed_test(rank, world_size):
    """æµ‹è¯•åˆ†å¸ƒå¼ç¯å¢ƒè®¾ç½®"""
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["MASTER_ADDR"] = "localhost"
        os.environ["MASTER_PORT"] = "12355"

        # è®¾ç½®CUDAè®¾å¤‡
        if torch.cuda.is_available():
            torch.cuda.set_device(rank % torch.cuda.device_count())
            print(f"[Rank {rank}] Using CUDA device: {torch.cuda.current_device()}")

        # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„
        torch.distributed.init_process_group(backend="nccl", rank=rank, world_size=world_size)
        print(f"[Rank {rank}] Distributed group initialized successfully")

        # æµ‹è¯•é€šä¿¡
        tensor = torch.tensor([rank], dtype=torch.float32)
        if torch.cuda.is_available():
            tensor = tensor.cuda()

        torch.distributed.all_reduce(tensor, op=torch.distributed.ReduceOp.SUM)
        print(f"[Rank {rank}] All reduce successful, result: {tensor.item()}")

        torch.distributed.destroy_process_group()
        return True

    except Exception as e:
        print(f"[Rank {rank}] Error: {e}")
        return False

def test_cuda():
    print("ğŸ” CUDA å¯ç”¨æ€§æµ‹è¯•")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")

        for i in range(torch.cuda.device_count()):
            device_props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {device_props.name} - {device_props.total_memory / 1024**3:.1f} GB")
            print(f"  - è®¡ç®—èƒ½åŠ›: {device_props.major}.{device_props.minor}")

        # æµ‹è¯• CUDA åˆå§‹åŒ–
        try:
            torch.cuda.init()
            print("âœ… CUDA åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ CUDA åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

        # æµ‹è¯•è®¾å¤‡è®¾ç½®
        try:
            for i in range(min(2, torch.cuda.device_count())):
                torch.cuda.set_device(i)
                print(f"âœ… è®¾å¤‡ {i} è®¾ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âŒ è®¾å¤‡è®¾ç½®å¤±è´¥: {e}")
            return False

        return True
    else:
        print("âŒ CUDA ä¸å¯ç”¨")
        return False

def test_vllm_import():
    """æµ‹è¯• vLLM æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¼å…¥"""
    try:
        from vllm import LLM, SamplingParams
        print("âœ… vLLM å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ vLLM å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_distributed():
    """æµ‹è¯• torch.distributed æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("\nğŸ” torch.distributed æµ‹è¯•")

    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡åˆ†å¸ƒå¼æµ‹è¯•")
        return True

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["MASTER_ADDR"] = "localhost"
        os.environ["MASTER_PORT"] = "12355"

        world_size = min(2, torch.cuda.device_count())  # æµ‹è¯•ä½¿ç”¨2ä¸ªGPU
        print(f"ä½¿ç”¨ {world_size} ä¸ªGPUè¿›è¡Œåˆ†å¸ƒå¼æµ‹è¯•")

        mp.spawn(setup_distributed_test, args=(world_size,), nprocs=world_size, join=True)
        print("âœ… torch.distributed æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ torch.distributed æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    cuda_ok = test_cuda()
    vllm_ok = test_vllm_import()
    dist_ok = test_distributed()

    print("\n" + "="*50)
    if cuda_ok and vllm_ok and dist_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥è¿è¡Œæ‰¹æ¨ç†è„šæœ¬äº†!")
    else:
        print("âš ï¸  å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è§£å†³åå†è¿è¡Œæ‰¹æ¨ç†è„šæœ¬")
        print(f"  - CUDA: {'âœ…' if cuda_ok else 'âŒ'}")
        print(f"  - vLLM: {'âœ…' if vllm_ok else 'âŒ'}")
        print(f"  - torch.distributed: {'âœ…' if dist_ok else 'âŒ'}")
