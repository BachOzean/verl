#!/bin/bash
export HYDRA_FULL_ERROR=1
export HF_ENDPOINT="https://hf-mirror.com"

# æ‰¹æ¨ç†å¯åŠ¨è„šæœ¬
HOME="/data/home/scyb494"

SCRIPT_PATH="$HOME/verl/eval/batch_inference.py"

# æ£€æŸ¥è„šæœ¬è·¯å¾„æ˜¯å¦å­˜åœ¨
if [ ! -f "$SCRIPT_PATH" ]; then
    echo "âŒ è„šæœ¬ä¸å­˜åœ¨: $SCRIPT_PATH"
    exit 1
fi

# é»˜è®¤å‚æ•°
MODEL="$HOME/models/DeepSeek-R1-Distill-Qwen-1.5B"
DATASET="/data/home/scyb494/.cache/huggingface/hub/datasets--open-r1--OpenR1-Math-220k/snapshots/e4e141ec9dea9f8326f4d347be56105859b2bd68/data"
SPLIT="train"
OUTPUT_DIR="$HOME/verl/eval/results/OpenR1-Math-220k"
NUM_SAMPLES=64
BATCH_SIZE=32
NUM_GPUS=4
GPU_MEMORY=0.75
# æ–°å¢ï¼šæ§åˆ¶é•¿åº¦ã€ç²¾åº¦ä¸å¹¶å‘
MAX_MODEL_LEN=4096
MAX_TOKENS=1024
DTYPE="bfloat16"   # å¯é€‰: auto|bfloat16|float16|float32
MAX_NUM_SEQS=1

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    key="$1"
    case $key in
        --model)
            MODEL="$2"
            shift 2
            ;;
        --dataset)
            DATASET="$2"
            shift 2
            ;;
        --split)
            SPLIT="$2"
            shift 2
            ;;
        --output_dir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --num_samples)
            NUM_SAMPLES="$2"
            shift 2
            ;;
        --batch_size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --num_gpus)
            NUM_GPUS="$2"
            shift 2
            ;;
        --gpu_memory)
            GPU_MEMORY="$2"
            shift 2
            ;;
        --max_model_len)
            MAX_MODEL_LEN="$2"
            shift 2
            ;;
        --max_tokens)
            MAX_TOKENS="$2"
            shift 2
            ;;
        --dtype)
            DTYPE="$2"
            shift 2
            ;;
        --max_num_seqs)
            MAX_NUM_SEQS="$2"
            shift 2
            ;;
        *)
            echo "âŒ æœªçŸ¥å‚æ•°: $1"
            echo "ç”¨æ³•: $0 --model <model_path> [å…¶ä»–å‚æ•°...]"
            exit 1
            ;;
    esac
done

# æ£€æŸ¥æ˜¯å¦æä¾›äº†æ¨¡å‹è·¯å¾„
if [ -z "$MODEL" ]; then
    echo "âŒ å¿…é¡»æä¾›æ¨¡å‹è·¯å¾„"
    echo "ç”¨æ³•: $0 --model <model_path> [å…¶ä»–å‚æ•°...]"
    echo ""
    echo "å¯é€‰å‚æ•°:"
    echo "  --dataset <dataset> (é»˜è®¤: open-r1/OpenR1-Math-220k)"
    echo "  --split <split> (é»˜è®¤: train)"
    echo "  --output_dir <dir> (é»˜è®¤: /home/ningmiao/ningyuan/verl/eval/results/OpenR1-Math-220k)"
    echo "  --num_samples <n> (é»˜è®¤: 64)"
    echo "  --batch_size <n> (é»˜è®¤: 32)"
    echo "  --num_gpus <n> (é»˜è®¤: 8)"
    echo "  --gpu_memory <fraction> (é»˜è®¤: 0.75)"
    echo "  --max_model_len <n> (é»˜è®¤: 4096)"
    echo "  --max_tokens <n> (é»˜è®¤: 1024)"
    echo "  --dtype <auto|bfloat16|float16|float32> (é»˜è®¤: bfloat16)"
    echo "  --max_num_seqs <n> (é»˜è®¤: 1)"
    exit 1
fi

echo "ğŸš€ å¯åŠ¨æ‰¹æ¨ç†..."
echo "  æ¨¡å‹: $MODEL"
echo "  æ•°æ®é›†: $DATASET"
echo "  è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "  æ ·æœ¬æ•°: $NUM_SAMPLES"
echo "  æ‰¹å¤§å°: $BATCH_SIZE"
echo "  GPUæ•°é‡: $NUM_GPUS"
echo "  GPUå†…å­˜åˆ©ç”¨ç‡: $GPU_MEMORY"
echo "  ä¸Šä¸‹æ–‡é•¿åº¦: $MAX_MODEL_LEN"
echo "  ç”Ÿæˆé•¿åº¦: $MAX_TOKENS"
echo "  ç²¾åº¦: $DTYPE"
echo "  å¹¶å‘åºåˆ—ä¸Šé™: $MAX_NUM_SEQS"

# è¿è¡Œæ‰¹æ¨ç†è„šæœ¬
exec python $SCRIPT_PATH \
    --model "$MODEL" \
    --dataset "$DATASET" \
    --split "$SPLIT" \
    --output_dir "$OUTPUT_DIR" \
    --num_samples "$NUM_SAMPLES" \
    --batch_size "$BATCH_SIZE" \
    --num_gpus "$NUM_GPUS" \
    --gpu_memory_utilization "$GPU_MEMORY" \
    --max_model_len "$MAX_MODEL_LEN" \
    --max_tokens "$MAX_TOKENS" \
    --dtype "$DTYPE" \
    --max_num_seqs "$MAX_NUM_SEQS"
